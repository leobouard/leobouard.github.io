---
layout: post
title: "Petit guide sur la performance en PowerShell"
description: "Tout savoir sur l'optimisation des performances sur vos scripts PowerShell"
tags: COURS
icon: üí™
listed: true
---

## Bien choisir ses tableaux

Je le connais, vous le connaissez, tout le monde le connait et l'utilise. Et pourtant, c'est la m√©thode la moins performante que l'on puisse choisir !

```powershell
$array = @()
1..10 | % { $array += $_ }
```

Comment √ßa marche ? Et bien la syntaxe tr√®s simple cache en fait un fonctionnement assez complexe.

Avec `@()`, vous allez cr√©er une collection de taille fixe avec une capacit√© maximum de 0 √©l√©ment. Comment agrandir la collection alors ? Gr√¢ce √† l'op√©rateur `+=`, on ne va pas ajouter un √©l√©ment √† la collection existante (puisque ce n'est pas possible) mais plut√¥t :

- cr√©er une nouvelle collection de taille fixe avec une capacit√© suffisante pour accueillir tous les √©l√©ments de l'ancienne collection + 1
- peupler la nouvelle collection en additionnant entre eux les √©l√©ments de l'ancienne collection et le nouvel √©l√©ment √† ajouter
- supprimer l'ancienne collection

En bref : un processus bien plus complexe que la syntaxe ne peut le laisser deviner. Pour r√©sum√©, le `+=` pourrait √™tre expliqu√© avec la syntaxe suivante :

```powershell
$array = @()
1..10 | % { $array = $array + @($_)}
```

Si vous voulez tout comprendre, voici l'article original : [Building Arrays and Collections in PowerShell \| Clear-Script](https://vexx32.github.io/2020/02/15/Building-Arrays-Collections/)

Lorsque vous cr√©er un array avec cette m√©thode, vous allez g√©n√©rer un tableau d'une taille fixe qui peut contenir un maximum de 0 √©l√©ment. Impossible donc d'y ajouter un membre avec la m√©thode `.Add()` qui donne l'erreur suivante : *Exception lors de l'appel de ¬´Add¬ª avec ¬´1¬ª argument(s): ¬´La collection √©tait d'une taille fixe.¬ª*.

Comment faire pour ajouter un nouvel √©l√©ment ? Avec l'op√©rateur `+=` voyons ! Et comment est-ce que cet op√©rateur fonctionne ? De la mani√®re la plus simple possible.

Comme il n'est pas possible d'agrandir l'array existant (qui est d'une taille fixe), la solution est donc de cr√©er un nouvel array 

PowerShell's + and += operators are designed to work with arrays in a relatively unusual way. When you try to add items to an array like this, what actually happens goes something like this:

PowerShell checks the size of the collection in $array and the number of items being added to it (in this case, just one each time).
PowerShell creates a completely different array of the correct size.
The original array is copied into this new array, along with the new item(s).
This is also why it's perfectly possible to join two arrays together with the + or += operators.


## Cr√©ation d'objet

New-Object -TypeName 'psobject' ... vs [PSCustomObject]@{}

## Bien comprendre le pipeline

On lit souvent que `foreach` est plus performant que `ForEach-Object`, ce n'est pas tout √† fait vrai : il s'agit simplement d'une utilisation diff√©rente.

La boucle `foreach` est en effet plus performante si toutes les donn√©es √† traiter ont d√©j√† √©t√© r√©cup√©r√©es.

L'avantage et l'inconv√©nient du `ForEach-Object`, c'est qu'il s'utilise avec un pipeline. Le pipeline (qui pourrait √™tre traduit grossi√®rement en *tuyau*) permet d'envoyer de la donn√©e d√®s qu'elle est disponible. Donc si vous faites une requ√™te avec 10000 objets en r√©sultat, le traitement via le pipeline permettra de commencer le travail d√®s que le premier objet est re√ßu.

Vous pouvez visualiser la diff√©rence avec les scripts suivants :

```powershell
function Test-Pipeline {
    1..100 | ForEach-Object { $_ ; Start-Sleep -Milliseconds 100 }
}

Test-Pipeline | ForEach-Object { 
    Write-Progress -Activity "Using 'ForEach-Object'" -PercentComplete $_
}

foreach ($_ in (Test-Pipeline)) { 
    Write-Progress -Activity "Using 'foreach()'" -PercentComplete $_
}
```

En r√©sum√© : si vous la liste de donn√©es √† traiter est instantan√©ment disponible (genre un fichier CSV), alors pr√©f√©rez l'utilisation de `foreach`. Si les donn√©es arrivent au fur et √† mesure (comme pour une requ√™te API par exemple), alors pr√©f√©rez le pipeline et `ForEach-Object`.

Pour tout savoir sur le pipeline : [Understanding PowerShell Pipeline \| PowerShell One](https://powershell.one/powershell-internals/scriptblocks/powershell-pipeline)

## Conna√Ætre son ennemi

Pour optimiser votre code, le plus important est d'identifier le goulot d'√©tranglement. Pour √ßa, vous pouvez utiliser la commande `Measure-Object` qui va mesurer le temps d'execution du code qui va se trouver entre les deux accolades. Certaines commandes sont plus gourmandes que d'autres (notamment les requ√™tes API, les cmdlet Exchange et Microsoft Graph) et le `Measure-Object` peut vous permettre de calculer pr√©cis√©ment le temps d'execution global, pour faire ensuite une belle barre de progression avec `Write-Progress` (notamment via le param√®tre `-SecondsRemaining`).

Voici un petit script qui permet de mesurer la dur√©e moyenne d'ex√©cution d'une commande ou d'un script PowerShell sur 100 it√©rations :

```powershell
$stats = foreach ($_ in 1..100) {
    Measure-Command -Expression { Get-LocalGroup }
}
$stats | Measure-Object -Property 'TotalSeconds' -Average
```

## Filtrer correctement

Tous les filtres ne se valent pas ! Une r√®gle de base peut √™tre facilement utilis√©e : faire les filtres les plus stricts (ceux qui √©liminerons le plus d'objets) en amont. Moins votre collection sera grande, plus votre script sera performant.

Point bonus : si votre collection est compos√©e de PSCustomObject, √©vitez de garder des propri√©t√©s inutile. L'id√©e c'est de raisonner en terme de poids total de votre collection, ce qui importe c'est le nombre d'objets et le nombre de propri√©t√©s par objet.

## Utiliser la parall√©lisation √† bon escient

Avec l'arriv√©e de PowerShell v7, la commande `ForEach-Object` r√©cup√®re un nouveau param√®tre : `-Parallel`. Ce param√®tre permet (comme son nom l'indique) de parall√©liser et donc de diviser le temps de traitement par le nombre d'instances (en g√©n√©ral : le nombre de CPU +1).

Si vous pouvez avoir acc√®s √† ce param√®tre, vous pouvez l'utilisez pour diminuer le temps d'ex√©cution de vos boucles `ForEach-Object`. Attention cependant : la parall√©lisation n'est pas "gratuite", et initier une nouvelle instance pour traiter un objet a un co√ªt.

Ainsi, sur certaines boucles tr√®s rapides, vous ne verrez pas d'am√©lioration voir pire : une d√©gradation des performances. Si vous voulez vous amusez, vous pouvez tester la diff√©rence entre `ForEach-Object` et `ForEach-Object -Parallel` sur des commandes simples avec la fonction suivante :

```powershell
function Test-Parallel {
    param(
        [string]$Command = '$PSItem',
        [int]$Iteration = 100
    )

    $scriptA = "(Measure-Command { 1..$Iteration | ForEach-Object { $Command } }).TotalMilliseconds"
    $scriptB = $scriptA -replace 'ForEach-Object','ForEach-Object -Parallel'

    $statRef = Invoke-Expression $scriptA
    $statDif = Invoke-Expression $scriptB
    $dif = $statRef/$statDif
    if ($statRef -lt $statDif) {
        [int]$dif = (1-$dif)*100
        $slowerOrFaster = 'rapide'
    } else {
        [int]$dif = ($dif-1)*100
        $slowerOrFaster = 'lente'
    }
    Write-Host "La boucle sans parall√©lisation est $dif`% plus $slowerOrFaster que la boucle avec parall√©lisation"
}
```

## Utiliser les bons outils

Vous aurez beau optimiser votre code comme jamais et suivre toutes les bonnes pratiques possibles, un script ex√©cut√© avec Windows PowerShell 2.0 sera toujours moins performant qu'un m√™me script ex√©cut√© en PowerShell v7. Les versions les plus r√©centes embarquent toujours leurs lot d'am√©liorations, autant au niveau des performances qu'au niveau des fonctionnalit√©s.

Voici un comparatif de temps de traitement sur plusieurs scripts diff√©rents, ex√©cut√©s sur la m√™me machine, sur des donn√©es locales uniquement (moyenne sur 100 ex√©cutions) :

Version | Script n¬∞1 | Script n¬∞2 | Script n¬∞3
------- | ---------- | ---------- | ----------
PowerShell 2.0 | 65ms | 70ms | 85ms
PowerShell 5.1 | 49ms | 49ms | 70ms
PowerShell 7.3 | 15ms | 10ms | 14ms

On observe PowerShell 7.3 fonctionne en moyenne **4x plus rapidement** que son anc√™tre PowerShell 2.0, avec un script identique (donc sans utiliser la parall√©lisation).

Pour suivre les derni√®res nouveaut√©s de PowerShell : [Overview of what's new in PowerShell \| Microsoft Learn](https://learn.microsoft.com/en-us/powershell/scripting/whats-new/overview?view=powershell-7.3)

## Se m√©fier de l'affichage dans la console

null = ... plut√¥t que Out-Null

N'importe quel type d'affichage dans une console va vous co√ªter du temps de traitement ! Que ce soit du `Format-Table`, du `Write-Progress` ou du `Write-Output` : rien √† faire, vous perdrez en performance.

Cependant, avant de tomber dans le dogmatisme je tiens √† pr√©ciser quelque chose d'important : la perte en temps vaut probablement le coup, et √ßa pour plusieurs raisons :

1. L'affichage dans la console est utile pour la journalisation et le d√©buggage d'un script. Un script qui s'ex√©cute vite, c'est bien. Un script qui fonctionne et qui est facile √† maintenir, c'est mieux !
2. Il ne faut pas sous-estimer la puissance d'une barre de progression pour le cerveau humain : le temps vous semblera infiniment moins long avec une barre qui se remplie petit √† petit, plut√¥t qu'une console vierge qui ne montre pas le moindre signe de progression.
3. Priorisez l'optimisation de vos performances : supprimer tout affichage dans votre script ne le rendra probablement pas deux fois plus performant. Essayer de trouver la cause du ralentissement avant de d√©gommer tous les `Write-Output` de votre script, car il y a de grandes chances pour √ßa ne soit pas la cause principale.

## Manger ~~bio~~ local

Une requ√™te AD pour obtenir 10000 utilisateurs est moins co√ªteuse que 10000 requ√™tes d'un seul utilisateur.

Morale de l'histoire : faire une grosse requ√™te pour requ√™ter ensuite √† l'int√©rieur du r√©sultat plut√¥t que de faire une requ√™te √† chaque fois.

Pour MSGraph : des rapports CSV sont disponibles (notamment pour les statistiques emails) qui permettent de gagner beaucoup de temps par rapport √† des requ√™tes individuelles.

## Conclusion
